{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1jqtWVHKcclLIumX0HikFpR51Yrtm1-Zc","timestamp":1766990509034}],"authorship_tag":"ABX9TyPgHuAFzgTPHnouy3rNgMGv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oPVcc8DuO65x"},"outputs":[],"source":["#@markdown # UST + LAB CORE GENERATOR\n","\n","import os\n","import random\n","import math\n","import shutil\n","from pathlib import Path\n","from collections import Counter\n","\n","\n","#@markdown ## Batch Control\n","\n","\n","#@markdown <font size=\"-1.5\"> _BATCH_COUNT = Number of ust+lab file will be generated_\n","BATCH_COUNT = 80  #@param {type:\"integer\", min:1, max:150}\n","\n","#@markdown <font size=\"-1.5\"> _PREFIX = Additional string added to the front of the generated files name_\n","PREFIX = 'default'#@param {type:\"string\"}\n","\n","\n","#@markdown ## Output Settings\n","MOUNTED_DRIVE_DIR = \"/content\"\n","FILE_PREFIX = PREFIX+\"dataset\"\n","\n","#@markdown ## Randomization Ranges\n","\n","#@markdown <font size=\"-1.5\"> _BASE_NOTE= Root note of the generated ust, is in midi format (36 = C2, 72 = C4)_\n","BASE_NOTE_MIN = 36 #@param {type:\"integer\", min:0, max:127}\n","BASE_NOTE_MAX = 72 #@param {type:\"integer\", min:0, max:127}\n","#@markdown <font size=\"-1.5\"> _SIGMA_VALUE= Standard distribution sigma value, determine the \"spreadiness\" of ust BASE_NOTE distribution_\n","SIGMA_VALUE = 0.25 #@param {type:\"number\", min:0,max:1}\n","\n","#@markdown <font size=\"-1.5\"> _NOTE_RANGE= Range between BASE_NOTE and the other note generated in the ust in semitones_\n","NOTE_RANGE_MIN = 4 #@param {type:\"integer\", min:1, max:20}\n","NOTE_RANGE_MAX = 5 #@param {type:\"integer\", min:1, max:20}\n","\n","\n","LENGTH_VARIANT_RANGE = (0.0, 1.0)\n","\n","#@markdown <font size=\"-1.5\"> _EXTRA_SP_RANGE= Making random SP appears in between the notes in ust generated_\n","EXTRA_SP_RANGE = (1, 3)\n","LENGTH_MODES = [\"normal\", \"short\", \"long\"]  # Length distribution modes\n","\n","BASE_NOTE_RANGE = (BASE_NOTE_MIN, BASE_NOTE_MAX)\n","NOTE_RANGE_RANGE = (NOTE_RANGE_MIN, NOTE_RANGE_MAX)\n","\n","#@markdown ## UST Settings\n","UST_FLAGS = \"g0B0H0P86\" #@param {type:\"string\"}\n","\n","# ------------------------\n","# Fixed Global Constants\n","# ------------------------\n","BPM = 120\n","TICKS_PER_BEAT = 480\n","TOTAL_TICKS = 24 * TICKS_PER_BEAT   # 6 bars * 4 beats\n","SP_TICK = 240                       # half beat\n","NOTE_LENGTHS = [240, 360, 480,600,720]\n","\n","# HTK Timing Constants (100ns units)\n","# 1 beat = 60/BPM seconds\n","# 1 tick = (60/BPM)/TICKS_PER_BEAT seconds\n","# 1 sec = 10,000,000 units (100ns)\n","TICK_TO_100NS = (60 / BPM / TICKS_PER_BEAT) * 10_000_000\n","\n","# Pitch Bend Timing Constants (milliseconds)\n","# 1 tick = (60/BPM)/TICKS_PER_BEAT seconds = (60/BPM)/TICKS_PER_BEAT * 1000 ms\n","TICK_TO_MS = (60 / BPM / TICKS_PER_BEAT) * 1000\n","\n","# -----------------------\n","# Japanese Hiragana Pools\n","# ------------------------\n","VOWELS = [\"ã‚\",\"ã„\",\"ã†\",\"ãˆ\",\"ãŠ\"]\n","\n","SINGLE_CV = [\n","    \"ã‹\",\"ã\",\"ã\",\"ã‘\",\"ã“\",\"ã•\",\"ã—\",\"ã™\",\"ã›\",\"ã\",\n","    \"ãŸ\",\"ã¡\",\"ã¤\",\"ã¦\",\"ã¨\",\"ãª\",\"ã«\",\"ã¬\",\"ã­\",\"ã®\",\n","    \"ã¯\",\"ã²\",\"ãµ\",\"ã¸\",\"ã»\",\"ã¾\",\"ã¿\",\"ã‚€\",\"ã‚\",\"ã‚‚\",\n","    \"ã‚‰\",\"ã‚Š\",\"ã‚‹\",\"ã‚Œ\",\"ã‚\",\"ãŒ\",\"ãŽ\",\"ã\",\"ã’\",\"ã”\",\n","    \"ã–\",\"ã˜\",\"ãš\",\"ãœ\",\"ãž\",\"ã \",\"ã¢\",\"ã¥\",\"ã§\",\"ã©\",\n","    \"ã°\",\"ã³\",\"ã¶\",\"ã¹\",\"ã¼\",\"ã±\",\"ã´\",\"ã·\",\"ãº\",\"ã½\",\n","    \"ã‚„\",\"ã‚†\",\"ã‚ˆ\",\"ã‚\",\"ã‚’\"\n","]\n","\n","YOON = [\n","    \"ãã‚ƒ\",\"ãã‚…\",\"ãã‚‡\",\"ã—ã‚ƒ\",\"ã—ã‚…\",\"ã—ã‚‡\",\"ã¡ã‚ƒ\",\"ã¡ã‚…\",\"ã¡ã‚‡\",\n","    \"ã«ã‚ƒ\",\"ã«ã‚…\",\"ã«ã‚‡\",\"ã²ã‚ƒ\",\"ã²ã‚…\",\"ã²ã‚‡\",\"ã¿ã‚ƒ\",\"ã¿ã‚…\",\"ã¿ã‚‡\",\n","    \"ã‚Šã‚ƒ\",\"ã‚Šã‚…\",\"ã‚Šã‚‡\",\"ãŽã‚ƒ\",\"ãŽã‚…\",\"ãŽã‚‡\",\"ã˜ã‚ƒ\",\"ã˜ã‚…\",\"ã˜ã‚‡\",\n","    \"ã³ã‚ƒ\",\"ã³ã‚…\",\"ã³ã‚‡\",\"ã´ã‚ƒ\",\"ã´ã‚…\",\"ã´ã‚‡\"\n","]\n","\n","SPECIAL = [\"ã‚“\"]\n","\n","# Distribution weights\n","LYRIC_WEIGHTS = (\n","    [\"vowel\"] * 1 +\n","    [\"single\"] * 10 +\n","    [\"double\"] * 6 +\n","    [\"special\"] * 1\n",")\n","\n","# -----------------------\n","# Target Phoneme Ratios\n","# ------------------------\n","TARGET_RATIO = {\n","    # Vowels (~60%)\n","    \"a\": 13.0,\n","    \"i\": 12.0,\n","    \"u\": 11.0,\n","    \"e\": 11.0,\n","    \"o\": 13.0,\n","\n","    # Special\n","    \"N\": 4.0,\n","    \"SP\": 7.0,\n","\n","    # Core consonants\n","    \"k\": 4.0,\n","    \"t\": 4.0,\n","    \"n\": 5.0,\n","    \"r\": 4.0,\n","    \"s\": 2.0,\n","    \"sh\": 2.5,\n","    \"m\": 2.0,\n","    \"p\": 2.0,\n","    \"g\": 2.0,\n","    \"d\": 2.0,\n","    \"z\": 1.5,\n","    \"b\": 1.0,\n","    \"h\": 1.0,\n","    \"y\": 1.0,\n","    \"w\": 1.5,\n","\n","    # Palatalized (low but non-zero)\n","    \"ky\": 1.2,\n","    \"gy\": 1.0,\n","    \"ch\": 1.2,\n","    \"ry\": 1.0,\n","    \"my\": 0.8,\n","    \"py\": 0.8,\n","    \"hy\": 0.8,\n","    \"ny\": 0.8,\n","    \"by\": 0.8,\n","}\n","\n","# -------------------------------\n","# Hiragana to Romaji Mapping Logic\n","# ---------------------------------\n","HIRAGANA_TO_ROMAJI = {\n","    # Vowels\n","    \"ã‚\": \"a\", \"ã„\": \"i\", \"ã†\": \"u\", \"ãˆ\": \"e\", \"ãŠ\": \"o\",\n","    # Single CV - K\n","    \"ã‹\": \"ka\", \"ã\": \"ki\", \"ã\": \"ku\", \"ã‘\": \"ke\", \"ã“\": \"ko\",\n","    # Single CV - S\n","    \"ã•\": \"sa\", \"ã—\": \"shi\", \"ã™\": \"su\", \"ã›\": \"se\", \"ã\": \"so\",\n","    # Single CV - T\n","    \"ãŸ\": \"ta\", \"ã¡\": \"chi\", \"ã¤\": \"tsu\", \"ã¦\": \"te\", \"ã¨\": \"to\",\n","    # Single CV - N\n","    \"ãª\": \"na\", \"ã«\": \"ni\", \"ã¬\": \"nu\", \"ã­\": \"ne\", \"ã®\": \"no\",\n","    # Single CV - H\n","    \"ã¯\": \"ha\", \"ã²\": \"hi\", \"ãµ\": \"fu\", \"ã¸\": \"he\", \"ã»\": \"ho\", # Changed fu to f and he to h here as well\n","    # Single CV - M\n","    \"ã¾\": \"ma\", \"ã¿\": \"mi\", \"ã‚€\": \"mu\", \"ã‚\": \"me\", \"ã‚‚\": \"mo\",\n","    # Single CV - R\n","    \"ã‚‰\": \"ra\", \"ã‚Š\": \"ri\", \"ã‚‹\": \"ru\", \"ã‚Œ\": \"re\", \"ã‚\": \"ro\",\n","    # Single CV - G\n","    \"ãŒ\": \"ga\", \"ãŽ\": \"gi\", \"ã\": \"gu\", \"ã’\": \"ge\", \"ã”\": \"go\",\n","    # Single CV - Z\n","    \"ã–\": \"za\", \"ã˜\": \"ji\", \"ãš\": \"zu\", \"ãœ\": \"ze\", \"ãž\": \"zo\",\n","    # Single CV - D\n","    \"ã \": \"da\", \"ã¢\": \"ji\", \"ã¥\": \"zu\", \"ã§\": \"de\", \"ã©\": \"do\",\n","    # Single CV - B\n","    \"ã°\": \"ba\", \"ã³\": \"bi\", \"ã¶\": \"bu\", \"ã¹\": \"be\", \"ã¼\": \"bo\",\n","    # Single CV - P\n","    \"ã±\": \"pa\", \"ã´\": \"pi\", \"ã·\": \"pu\", \"ãº\": \"pe\", \"ã½\": \"po\",\n","    # Single CV - Y/W\n","    \"ã‚„\": \"ya\", \"ã‚†\": \"yu\", \"ã‚ˆ\": \"yo\", \"ã‚\": \"wa\", \"ã‚’\": \"wo\",\n","    # YOON - K\n","    \"ãã‚ƒ\": \"kya\", \"ãã‚…\": \"kyu\", \"ãã‚‡\": \"kyo\",\n","    # YOON - S\n","    \"ã—ã‚ƒ\": \"sha\", \"ã—ã‚…\": \"shu\", \"ã—ã‚‡\": \"sho\",\n","    # YOON - T\n","    \"ã¡ã‚ƒ\": \"cha\", \"ã¡ã‚…\": \"chu\", \"ã¡ã‚‡\": \"cho\",\n","    # YOON - N\n","    \"ã«ã‚ƒ\": \"nya\", \"ã«ã‚…\": \"nyu\", \"ã«ã‚‡\": \"nyo\",\n","    # YOON - H\n","    \"ã²ã‚ƒ\": \"hya\", \"ã²ã‚…\": \"hyu\", \"ã²ã‚‡\": \"hyo\",\n","    # YOON - M\n","    \"ã¿ã‚ƒ\": \"mya\", \"ã¿ã‚…\": \"myu\", \"ã¿ã‚‡\": \"myo\",\n","    # YOON - R\n","    \"ã‚Šã‚ƒ\": \"rya\", \"ã‚Šã‚…\": \"ryu\", \"ã‚Šã‚‡\": \"ryo\",\n","    # YOON - G\n","    \"ãŽã‚ƒ\": \"gya\", \"ãŽã‚…\": \"gyu\", \"ãŽã‚‡\": \"gyo\",\n","    # YOON - J\n","    \"ã˜ã‚ƒ\": \"ja\", \"ã˜ã‚…\": \"ju\", \"ã˜ã‚‡\": \"jo\",\n","    # YOON - B\n","    \"ã³ã‚ƒ\": \"bya\", \"ã³ã‚…\": \"byu\", \"ã³ã‚‡\": \"byo\",\n","    # YOON - P\n","    \"ã´ã‚ƒ\": \"pya\", \"ã´ã‚…\": \"pyu\", \"ã´ã‚‡\": \"pyo\",\n","    # Special\n","    \"ã‚“\": \"n\"\n","}\n","\n","def hiragana_to_romaji(hiragana):\n","    \"\"\"Convert hiragana to romaji. Returns the original string if not found in mapping.\"\"\"\n","    return HIRAGANA_TO_ROMAJI.get(hiragana, hiragana)\n","\n","# ---------------------------\n","# Phoneme Decomposition Logic\n","# ---------------------------\n","HIRAGANA_TO_PHONEME = {\n","    # Vowels (keep as is)\n","    \"ã‚\": \"a\", \"ã„\": \"i\", \"ã†\": \"u\", \"ãˆ\": \"e\", \"ãŠ\": \"o\",\n","    # Single CV - K\n","    \"ã‹\": \"k\", \"ã\": \"k\", \"ã\": \"k\", \"ã‘\": \"k\", \"ã“\": \"k\",\n","    # Single CV - S\n","    \"ã•\": \"s\", \"ã—\": \"sh\", \"ã™\": \"s\", \"ã›\": \"s\", \"ã\": \"s\",\n","    # Single CV - T\n","    \"ãŸ\": \"t\", \"ã¡\": \"ch\", \"ã¤\": \"ts\", \"ã¦\": \"t\", \"ã¨\": \"t\",\n","    # Single CV - N\n","    \"ãª\": \"n\", \"ã«\": \"n\", \"ã¬\": \"n\", \"ã­\": \"n\", \"ã®\": \"n\",\n","    # Single CV - H\n","    \"ã¯\": \"h\", \"ã²\": \"h\", \"ãµ\": \"f\", \"ã¸\": \"h\", \"ã»\": \"h\",\n","    # Single CV - M\n","    \"ã¾\": \"m\", \"ã¿\": \"m\", \"ã‚€\": \"m\", \"ã‚\": \"m\", \"ã‚‚\": \"m\",\n","    # Single CV - R\n","    \"ã‚‰\": \"r\", \"ã‚Š\": \"r\", \"ã‚‹\": \"r\", \"ã‚Œ\": \"r\", \"ã‚\": \"r\",\n","    # Single CV - G\n","    \"ãŒ\": \"g\", \"ãŽ\": \"g\", \"ã\": \"g\", \"ã’\": \"g\", \"ã”\": \"g\",\n","    # Single CV - Z\n","    \"ã–\": \"z\", \"ã˜\": \"j\", \"ãš\": \"z\", \"ãœ\": \"z\", \"ãž\": \"z\",\n","    # Single CV - D\n","    \"ã \": \"d\", \"ã¢\": \"j\", \"ã¥\": \"z\", \"ã§\": \"d\", \"ã©\": \"d\",\n","    # Single CV - B\n","    \"ã°\": \"b\", \"ã³\": \"b\", \"ã¶\": \"b\", \"ã¹\": \"b\", \"ã¼\": \"b\",\n","    # Single CV - P\n","    \"ã±\": \"p\", \"ã´\": \"p\", \"ã·\": \"p\", \"ãº\": \"p\", \"ã½\": \"p\",\n","    # Single CV - Y/W\n","    \"ã‚„\": \"y\", \"ã‚†\": \"y\", \"ã‚ˆ\": \"y\", \"ã‚\": \"w\", \"ã‚’\": \"w\",\n","    # Special\n","    \"ã‚“\": \"N\"\n","}\n","\n","# Vowel mapping for yoon\n","YOON_VOWEL_MAP = {\n","    \"ã‚ƒ\": \"a\", \"ã‚…\": \"u\", \"ã‚‡\": \"o\"\n","}\n","\n","NOTE_NAMES = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n","\n","\n","def extract_track_name_from_voicepart(voicepart_name: str) -> str:\n","    \"\"\"\n","    Convert a voice_part name like:\n","        mzo_neutral_001_A3_9\n","    into:\n","        001_A3_9\n","    \"\"\"\n","    parts = voicepart_name.split(\"_\")\n","    if len(parts) >= 3:\n","        return \"_\".join(parts[-3:])\n","    return voicepart_name\n","\n","\n","\n","def generate_singer_tracks_from_voiceparts(\n","    voice_parts: list,\n","    default_singer: str,\n","    phonemizer: str,\n","    renderer_settings: dict\n",") -> list:\n","    \"\"\"\n","    Generate USTX singer tracks where track_name is derived\n","    from the corresponding voice_part.name.\n","    \"\"\"\n","    tracks = {}\n","\n","    for vp in voice_parts:\n","        track_no = vp[\"track_no\"]  # 1-based\n","        if track_no not in tracks:\n","            track_name = extract_track_name_from_voicepart(vp[\"name\"])\n","            tracks[track_no] = {\n","                \"singer\": default_singer,\n","                \"phonemizer\": phonemizer,\n","                \"renderer_settings\": renderer_settings,\n","                \"track_name\": track_name,\n","                \"track_color\": \"Blue\",\n","                \"mute\": False,\n","                \"solo\": False,\n","                \"volume\": 0,\n","                \"pan\": 0,\n","                \"track_expressions\": [],\n","                \"voice_color_names\": [\"\"],\n","            }\n","\n","    # Return tracks sorted by track_no\n","    return [tracks[k] for k in sorted(tracks.keys())]\n","\n","def pick_base_note_gaussian(\n","    base_note_min: int,\n","    base_note_max: int,\n","    batch_count: int,\n","    sigma_scale: float = 0.25\n",") -> int:\n","    \"\"\"\n","    Pick a base note using a normal (Gaussian) distribution,\n","    centered in the allowed range, but still randomized.\n","\n","    Args:\n","        base_note_min: minimum MIDI note\n","        base_note_max: maximum MIDI note\n","        batch_count: total number of files being generated\n","        sigma_scale: controls spread (0.15 = tight, 0.3 = wide)\n","\n","    Returns:\n","        int: selected base_note (MIDI)\n","    \"\"\"\n","    center = (base_note_min + base_note_max) / 2\n","\n","    # Wider distribution when generating more files\n","    note_range = base_note_max - base_note_min\n","    sigma = max(1.0, note_range * sigma_scale)\n","\n","    for _ in range(10):  # retry to stay in bounds\n","        value = int(round(random.gauss(center, sigma)))\n","        if base_note_min <= value <= base_note_max:\n","            return value\n","\n","    # Fallback (uniform random if gaussian fails repeatedly)\n","    return random.randint(base_note_min, base_note_max)\n","\n","\n","def midi_to_note_name(midi_note: int) -> str:\n","    \"\"\"\n","    Convert MIDI note number to scientific pitch notation.\n","\n","    Examples:\n","        0  -> C-1\n","        12 -> C0\n","        24 -> C1\n","        30 -> F#1\n","        47 -> B2\n","    \"\"\"\n","    note_name = NOTE_NAMES[midi_note % 12]\n","    octave = (midi_note // 12) - 1\n","    return f\"{note_name}{octave}\"\n","\n","def decompose_lyric(lyric):\n","    \"\"\"Decompose hiragana lyric into phonemes for LAB file.\"\"\"\n","    if lyric == \"SP\":\n","        return [\"SP\"]\n","\n","    if lyric in VOWELS:\n","        # Vowels stay as single phoneme\n","        return [HIRAGANA_TO_PHONEME.get(lyric, lyric)]\n","\n","    if lyric == \"ã‚“\":\n","        return [\"N\"]\n","\n","    if len(lyric) == 1:\n","        # Single CV: decompose into consonant + vowel\n","        # e.g., \"ãŸ\" (ta) -> [\"t\", \"a\"], \"ã”\" (go) -> [\"g\", \"o\"]\n","        consonant = HIRAGANA_TO_PHONEME.get(lyric, \"\")\n","        if not consonant:\n","            return [lyric]\n","\n","        # Get vowel from romaji mapping\n","        romaji = HIRAGANA_TO_ROMAJI.get(lyric, \"\")\n","        if len(romaji) > 1:\n","            # Extract vowel (last character)\n","            vowel = romaji[-1]\n","            return [consonant, vowel]\n","        # If romaji is single char, it's likely a vowel or special case\n","        return [consonant]\n","\n","    if len(lyric) == 2:  # yÅon (e.g., 'ãã‚ƒ', 'ã—ã‚‡')\n","        # e.g., \"ãã‚ƒ\" (kya) -> [\"ky\", \"a\"], \"ã—ã‚ƒ\" (sha) -> [\"sh\", \"a\"]\n","        consonant_char = lyric[0]\n","        yoon_char = lyric[1]\n","        consonant = HIRAGANA_TO_PHONEME.get(consonant_char, \"\")\n","        vowel = YOON_VOWEL_MAP.get(yoon_char, \"\")\n","\n","        if consonant and vowel:\n","            # Only add 'y' for single-character consonants (k, s, t, etc.)\n","            # Multi-character consonants (sh, ch, ts, j) should remain as-is\n","            if len(consonant) == 1:\n","                return [consonant + \"y\", vowel]\n","            else:\n","                return [consonant, vowel]\n","        # Fallback if mapping fails\n","        return [lyric]\n","\n","    # Fallback\n","    return [lyric]\n","\n","def get_hiragana_phoneme_map():\n","    \"\"\"Create a mapping from hiragana to the phonemes it produces.\"\"\"\n","    mapping = {}\n","    all_hiragana = VOWELS + SINGLE_CV + YOON + SPECIAL\n","\n","    for hiragana in all_hiragana:\n","        mapping[hiragana] = decompose_lyric(hiragana)\n","\n","    return mapping\n","\n","# Pre-compute hiragana to phoneme mapping\n","HIRAGANA_PHONEME_MAP = get_hiragana_phoneme_map()\n","\n","# ---------------------------\n","# Template / Sample Config Loading\n","# ---------------------------\n","def load_ust_header(path=None):\n","    default_header = [\"[#SETTING]\", \"Tempo=120\"]\n","    if path is None or not os.path.exists(path):\n","        return default_header\n","\n","    header = []\n","    try:\n","        with open(path, 'r', encoding='utf-8') as f:\n","            for line in f:\n","                line = line.strip()\n","                if line.startswith('[#0') or line.startswith('[#TRACK'):\n","                    break\n","                if line:\n","                    header.append(line)\n","    except Exception as e:\n","        print(f\"Warning: Could not read UST header: {e}\")\n","        return default_header\n","    return header\n","\n","def detect_lab_format(path=None):\n","    \"\"\"Returns 'htk' if timed (start end phn), else 'simple' (phn phn ...)\"\"\"\n","    if path is None or not os.path.exists(path):\n","        return 'htk'  # Default to HTK format\n","    try:\n","        with open(path, 'r', encoding='utf-8') as f:\n","            for line in f:\n","                parts = line.strip().split()\n","                # Check for HTK format: start_time end_time phoneme\n","                if len(parts) >= 3 and parts[0].replace('.','',1).isdigit():\n","                    return 'htk'\n","                if line.strip():\n","                    break\n","    except:\n","        pass\n","    return 'simple'\n","\n","# Pre-load configuration\n","UST_HEADER_TEMPLATE = load_ust_header()\n","LAB_OUTPUT_FORMAT = detect_lab_format()\n","print(f\"Generator Configured: UST Header lines={len(UST_HEADER_TEMPLATE)}, LAB Format={LAB_OUTPUT_FORMAT}\")\n","\n","# -----------------------------------\n","# OpenUTAU Pitch Curves & Vibrato Logic\n","# -----------------------------------\n","def generate_pitch_curve(note_length_ticks, current_note_pitch, next_note_length_ticks=None, next_note_pitch=None):\n","    \"\"\"\n","    Generate PBS, PBW, PBY, and PBM following UTAU Mode2 pitchbend rules.\n","\n","    PBS: start_time;start_pitch\n","      - start_time: 10-25% of current note length, negative value (ms)\n","      - start_pitch: based on pitch difference between current and next note (decacents)\n","\n","    PBW: comma-separated widths in ms between control points\n","      - Final PBW should not exceed 25% of next note's length\n","      - Calculated based on pitchBendTotalWidth\n","\n","    PBY: comma-separated pitch offsets in decacents for control points after first\n","      - Final point must have PBY = 0\n","      - All values between -200 and 200\n","\n","    PBM: interpolation mode string (empty = S-curve, 's' = linear, 'j' = J-curve, 'r' = R-curve)\n","\n","    Args:\n","        note_length_ticks: Length of the current note in ticks\n","        current_note_pitch: MIDI note number of current note\n","        next_note_length_ticks: Length of next note in ticks (None if last note)\n","        next_note_pitch: MIDI note number of next note (None if last note)\n","\n","    Returns:\n","        tuple: (PBS, PBW, PBY, PBM) strings\n","    \"\"\"\n","    # Convert note length to milliseconds\n","    note_length_ms = note_length_ticks * TICK_TO_MS\n","\n","    # Generate PBS: start_time;start_pitch\n","    # a. start_time: 10-25% of current note's length, negative value\n","    start_time_percent = random.uniform(0.10, 0.25)\n","    start_time = -(note_length_ms * start_time_percent)\n","\n","    # b. start_pitch: based on pitch difference between current and next note\n","    # 1 semitone = 10 decacents\n","    # If next note is higher, start_pitch is negative (slide up)\n","    # If next note is lower, start_pitch is positive (slide down)\n","    if next_note_pitch is not None:\n","        pitch_diff_semitones = next_note_pitch - current_note_pitch\n","        start_pitch = -pitch_diff_semitones * 10  # Convert to decacents, negate for slide direction\n","    else:\n","        # Last note: use small random value\n","        start_pitch = random.uniform(-20, 20)\n","\n","    # Format PBS with appropriate precision\n","    if abs(start_time - round(start_time)) < 0.001:\n","        start_time_str = str(int(round(start_time)))\n","    else:\n","        start_time_str = f\"{start_time:.5f}\"\n","\n","    if abs(start_pitch - round(start_pitch)) < 0.001:\n","        start_pitch_str = str(int(round(start_pitch)))\n","    else:\n","        precision = random.choice([1, 2, 5])\n","        start_pitch_str = f\"{start_pitch:.{precision}f}\"\n","\n","    pbs = f\"{start_time_str};{start_pitch_str}\"\n","\n","    # Generate PBW & PBY\n","    # 1. Final point should have PBY = 0, PBW should not be more than 25% of next note's length\n","    if next_note_length_ticks is not None:\n","        next_note_length_ms = next_note_length_ticks * TICK_TO_MS\n","        max_final_position = next_note_length_ms * 0.25  # Maximum absolute position (ms from note start)\n","    else:\n","        # Last note: use note_length_ms as max\n","        max_final_position = note_length_ms * 0.25\n","\n","    # 2. Define pitchBendTotalWidth = last_pbw_point - start_time\n","    # last_pbw_point is the final absolute position, must be <= max_final_position\n","    # start_time is negative, so we need to ensure: start_time + pitchBendTotalWidth <= max_final_position\n","    # Therefore: pitchBendTotalWidth <= max_final_position - start_time\n","\n","    # Calculate maximum allowed pitchBendTotalWidth\n","    max_pitchBendTotalWidth = max_final_position - start_time\n","\n","    # Choose a final position within the allowed range\n","    # Final position should be between start_time and max_final_position\n","    # We want it to be reasonable, so let's use a portion of the available range\n","    # But we must ensure it never exceeds max_final_position\n","    target_final_position = note_length_ms * random.uniform(0.5, 0.9)\n","\n","    # Clamp to maximum allowed position\n","    final_position = min(target_final_position, max_final_position)\n","\n","    # Ensure final_position is reasonable (at least some distance from start_time)\n","    # Since start_time is negative, final_position should be positive\n","    final_position = max(final_position, abs(start_time) + 20)  # At least 20ms after note start\n","\n","    # Re-clamp after adjustment\n","    final_position = min(final_position, max_final_position)\n","\n","    # Calculate pitchBendTotalWidth\n","    pitchBendTotalWidth = final_position - start_time\n","\n","    # Ensure we don't exceed the maximum allowed\n","    pitchBendTotalWidth = min(pitchBendTotalWidth, max_pitchBendTotalWidth)\n","\n","    # Recalculate final_position based on clamped pitchBendTotalWidth\n","    final_position = start_time + pitchBendTotalWidth\n","\n","    # 3. PBW values should be between PBS start_time and final PBW point\n","    # 4. num_points = floor(pitchBendTotalWidth / 100)\n","    num_points = max(1, int(math.floor(pitchBendTotalWidth / 100)))\n","\n","    # 5. Calculate PBW using formula: (pitchBendTotalWidth * num_points_index) / (num_points + 1)\n","    # This gives cumulative positions, we need to convert to widths (differences)\n","    if num_points == 1:\n","        # Single point: no widths needed\n","        pbw_values = []\n","    else:\n","        # Calculate cumulative positions\n","        positions = []\n","        positions.append(start_time)  # Position 0 = start_time\n","        for i in range(1, num_points + 1):  # i from 1 to num_points\n","            # Cumulative position from start_time\n","            position = start_time + (pitchBendTotalWidth * i) / (num_points + 1)\n","            positions.append(position)\n","\n","        # Convert positions to widths (differences between consecutive positions)\n","        pbw_values = []\n","        for i in range(len(positions) - 1):\n","            width = positions[i + 1] - positions[i]\n","            pbw_values.append(width)\n","\n","        # Critical check: Verify final cumulative position is within limit\n","        # The final position is: start_time + sum of all PBW values\n","        final_cumulative = start_time + sum(pbw_values)\n","\n","        if final_cumulative > max_final_position:\n","            # We exceeded the limit - need to adjust\n","            excess = final_cumulative - max_final_position\n","\n","            # Option 1: Reduce the last PBW value\n","            if len(pbw_values) > 0 and pbw_values[-1] > excess:\n","                pbw_values[-1] = pbw_values[-1] - excess\n","            else:\n","                # Option 2: Scale down all PBW values proportionally\n","                if sum(pbw_values) > 0:\n","                    scale_factor = (max_final_position - start_time) / sum(pbw_values)\n","                    pbw_values = [w * scale_factor for w in pbw_values]\n","\n","        # Final verification: double-check the cumulative position\n","        final_cumulative_check = start_time + sum(pbw_values)\n","        if final_cumulative_check > max_final_position:\n","            # Last resort: clamp to exactly the limit\n","            total_width = sum(pbw_values)\n","            if total_width > 0:\n","                scale = (max_final_position - start_time) / total_width\n","                pbw_values = [w * scale for w in pbw_values]\n","\n","    # Format PBW values\n","    if not pbw_values:\n","        pbw = \"\"\n","    else:\n","        pbw_strs = []\n","        for val in pbw_values:\n","            if abs(val - round(val)) < 0.001:\n","                pbw_strs.append(str(int(round(val))))\n","            else:\n","                precision = random.choice([0, 1, 2, 5])\n","                pbw_strs.append(f\"{val:.{precision}f}\")\n","        pbw = \",\".join(pbw_strs)\n","\n","    # Generate PBY: pitch offsets in decacents for control points after first\n","    # PBY has num_points values (for points 1 through num_points)\n","    # 1. Final point must have PBY = 0\n","    # 4. PBY can only be between -200 and 200\n","    if num_points == 1:\n","        # Single point: no PBY values needed\n","        pby = \"\"\n","    else:\n","        pby_values = []\n","        current_pitch = start_pitch\n","\n","        # Generate pitches for points 1 through num_points-1 (not including final)\n","        for i in range(num_points - 1):\n","            # Interpolate towards 0 (final point)\n","            # Gradually move from start_pitch towards 0\n","            progress = (i + 1) / num_points  # 0 to 1\n","            target_pitch = start_pitch * (1 - progress)\n","\n","            # Add some randomness but keep within -200 to 200\n","            variation = random.uniform(-20, 20)\n","            new_pitch = target_pitch + variation\n","            new_pitch = max(-200, min(200, new_pitch))\n","\n","            pby_values.append(new_pitch)\n","            current_pitch = new_pitch\n","\n","        # Final point: PBY = 0\n","        pby_values.append(0)\n","\n","        # Format PBY values\n","        pby_strs = []\n","        for val in pby_values:\n","            if abs(val - round(val)) < 0.001:\n","                pby_strs.append(str(int(round(val))))\n","            else:\n","                precision = random.choice([1, 2, 5])\n","                pby_strs.append(f\"{val:.{precision}f}\")\n","        pby = \",\".join(pby_strs)\n","\n","    # Generate PBM: interpolation mode string\n","    # PBM has num_points characters (one for each interval)\n","    # Empty/blank = S-curve (default), 's' = linear, 'j' = J-curve, 'r' = R-curve\n","    if num_points == 1:\n","        # Single point: no intervals, so no PBM\n","        pbm = \"\"\n","    elif random.random() < 0.8:  # 80% chance for default S-curve (empty)\n","        pbm = \"\"\n","    else:  # 20% chance for other modes\n","        modes = ['s', 'j', 'r']\n","        pbm = \"\".join(random.choice(modes) for _ in range(num_points))\n","\n","    return pbs, pbw, pby, pbm\n","\n","def vibrato_params():\n","    \"\"\"Randomly selects vibrato mode and generates parameters for each note.\"\"\"\n","    # Randomly choose vibrato mode: none (30%), medium (50%), high (20%)\n","    mode = random.choices(\n","        [\"none\", \"medium\", \"high\"],\n","        weights=[30, 50, 20]\n","    )[0]\n","\n","    if mode == \"none\":\n","        return \"\"\n","\n","    if mode == \"medium\":\n","        base = {\n","            \"len\": 60,\n","            \"freq\": 150,\n","            \"depth\": 25.0,\n","            \"in\": 30,\n","            \"out\": 30\n","        }\n","    else:  # high\n","        base = {\n","            \"len\": 75,\n","            \"freq\": 220,\n","            \"depth\": 45.0,\n","            \"in\": 40,\n","            \"out\": 40\n","        }\n","\n","    v_len = random.randint(int(base[\"len\"] * 0.6), base[\"len\"])\n","    v_freq = random.randint(100, min(base[\"freq\"], 250))\n","    v_depth = round(random.uniform(base[\"depth\"] * 0.6, base[\"depth\"]), 2)\n","\n","    return f\"{v_len},{v_freq},{v_depth},{base['in']},{base['out']},0,0\"\n","\n","# ---------------------------\n","# Random Selection & Pickers\n","# ---------------------------\n","def pick_lyric():\n","    \"\"\"Picks a lyric randomly based on LYRIC_WEIGHTS distribution.\"\"\"\n","    pool = random.choice(LYRIC_WEIGHTS)\n","    if pool == \"vowel\":\n","        return random.choice(VOWELS)\n","    if pool == \"single\":\n","        return random.choice(SINGLE_CV)\n","    return random.choice(YOON)\n","\n","def calculate_phoneme_weights(current_counts, total_count, target_ratio):\n","    \"\"\"\n","    Calculate weights for hiragana selection based on current phoneme ratios vs targets.\n","\n","    Args:\n","        current_counts: dict of current phoneme counts\n","        total_count: total number of phonemes generated so far\n","        target_ratio: dict of target ratios\n","\n","    Returns:\n","        dict: weights for each hiragana\n","    \"\"\"\n","    if total_count == 0:\n","        # Equal weights at start\n","        return {h: 1.0 for h in VOWELS + SINGLE_CV + YOON + SPECIAL}\n","\n","    weights = {}\n","    all_hiragana = VOWELS + SINGLE_CV + YOON + SPECIAL\n","\n","    for hiragana in all_hiragana:\n","        phonemes = HIRAGANA_PHONEME_MAP.get(hiragana, [])\n","        if not phonemes:\n","            weights[hiragana] = 1.0\n","            continue\n","\n","        # Calculate how much each phoneme from this hiragana needs boosting\n","        boost_factor = 1.0\n","        for phoneme in phonemes:\n","            if phoneme == \"SP\":  # Skip SP in ratio calculations\n","                continue\n","\n","            current_ratio = (current_counts.get(phoneme, 0) / total_count * 100) if total_count > 0 else 0\n","            target = target_ratio.get(phoneme, 0)\n","\n","            if target > 0:\n","                # If below 70% of target, boost significantly\n","                threshold = target * 0.7\n","                if current_ratio < threshold:\n","                    # Boost more if further below threshold\n","                    deficit = threshold - current_ratio\n","                    boost = 1.0 + (deficit / target) * 3.0  # Up to 4x boost\n","                    boost_factor = max(boost_factor, boost)\n","                elif current_ratio > target * 1.5:\n","                    # Reduce if way above target\n","                    excess = current_ratio - target\n","                    reduction = 1.0 - (excess / target) * 0.3  # Up to 30% reduction\n","                    boost_factor = min(boost_factor, max(0.1, reduction))\n","\n","        weights[hiragana] = boost_factor\n","\n","    return weights\n","\n","def pick_lyric_weighted(\n","    current_counts,\n","    total_count,\n","    target_ratio,\n","    blocked_phonemes=None\n","):\n","\n","    \"\"\"\n","    Pick a lyric with weights based on phoneme ratio targets.\n","\n","    Args:\n","        current_counts: dict of current phoneme counts\n","        total_count: total number of phonemes generated\n","        target_ratio: dict of target ratios\n","\n","    Returns:\n","        str: selected hiragana\n","    \"\"\"\n","    if current_counts is None or target_ratio is None:\n","        # Fallback to original random selection\n","        return pick_lyric()\n","\n","    if blocked_phonemes is None:\n","        blocked_phonemes = set()\n","\n","    weights = calculate_phoneme_weights(current_counts, total_count, target_ratio)\n","\n","    for h, phs in HIRAGANA_PHONEME_MAP.items():\n","        if any(p in blocked_phonemes for p in phs):\n","            weights[h] = 0.0\n","\n","    # Separate by pool\n","    vowel_weights = [weights.get(v, 1.0) for v in VOWELS]\n","    single_weights = [weights.get(s, 1.0) for s in SINGLE_CV]\n","    yoon_weights = [weights.get(y, 1.0) for y in YOON]\n","    special_weights = weights.get(\"ã‚“\", 1.0)\n","\n","    # Weight pool selection based on average weights\n","    pool_weights = [\n","        sum(vowel_weights) / len(vowel_weights) if vowel_weights else 1.0,  # vowel\n","        sum(single_weights) / len(single_weights) if single_weights else 1.0,  # single\n","        sum(yoon_weights) / len(yoon_weights) if yoon_weights else 1.0,  # yoon\n","        special_weights\n","    ]\n","\n","    pool = random.choices([\"vowel\", \"single\", \"yoon\",'special'], weights=pool_weights)[0]\n","\n","    if pool == \"vowel\":\n","        return random.choices(VOWELS, weights=vowel_weights)[0]\n","    elif pool == \"single\":\n","        return random.choices(SINGLE_CV, weights=single_weights)[0]\n","    elif pool == \"special\":\n","        return \"ã‚“\"\n","    else:\n","        return random.choices(YOON, weights=yoon_weights)[0]\n","\n","def pick_length(length_mode=\"normal\"):\n","    \"\"\"\n","    Pick a note length based on weighted distribution.\n","\n","    Args:\n","        length_mode: \"normal\" (equal weights), \"short\" (favor shorter), \"long\" (favor longer)\n","\n","    Returns:\n","        int: Note length in ticks\n","    \"\"\"\n","    if length_mode == \"normal\":\n","        # Equal probability for all lengths\n","        weights = [1, 1, 1, 1, 1]\n","    elif length_mode == \"short\":\n","        # Favor shorter lengths: 240 > 480 > 720 > 960\n","        weights = [2, 4, 2, 1,0]\n","    elif length_mode == \"long\":\n","        # Favor longer lengths: 960 > 720 > 480 > 240\n","        weights = [0, 3, 4,3,2]\n","    else:\n","        # Default to normal if invalid mode\n","        weights = [1, 1, 1 , 1, 1]\n","\n","    return random.choices(NOTE_LENGTHS, weights=weights)[0]\n","\n","def pick_note(base_note, note_range):\n","    return random.randint(\n","        base_note,\n","        min(base_note + note_range, 106)\n","    )\n","\n","def validate_phoneme_ratios(\n","    phoneme_counts,\n","    target_ratio,\n","    under_threshold=0.7,\n","    over_threshold=1.1\n","):\n","    total = sum(phoneme_counts.values())\n","    if total == 0:\n","        return False, {}, {}, \"No phonemes counted\"\n","\n","    under = {}\n","    over = {}\n","    current_ratios = {}\n","\n","    for phoneme, target in target_ratio.items():\n","        if phoneme == \"SP\" or phoneme == \"trash\":\n","            continue\n","\n","        current = phoneme_counts.get(phoneme, 0)\n","        ratio = (current / total) * 100\n","        current_ratios[phoneme] = ratio\n","        threshold_ratio = target * under_threshold\n","\n","        if ratio < threshold_ratio:\n","            print(f\"phoneme {phoneme} is underepresented (ratio: {ratio},threshold: {threshold_ratio})\")\n","            under[phoneme] = {\n","                \"current\": ratio,\n","                \"target\": target,\n","                \"threshold\": target * under_threshold\n","            }\n","        elif ratio > target * over_threshold:\n","            over[phoneme] = {\n","                \"current\": ratio,\n","                \"target\": target,\n","                \"threshold\": target * over_threshold\n","            }\n","\n","    is_valid = not under and not over\n","\n","    report = [\n","        f\"Validation: {'PASS' if is_valid else 'FAIL'}\",\n","        f\"Total phonemes: {total}\",\n","        f\"Underrepresented: {len(under)}\",\n","        f\"Overrepresented: {len(over)}\",\n","    ]\n","\n","    if under:\n","        report.append(\"\\nUnderrepresented phonemes:\")\n","        for k, v in under.items():\n","            report.append(f\"  {k}: {v['current']:.2f}% < {v['threshold']:.2f}%\")\n","\n","    if over:\n","        report.append(\"\\nOverrepresented phonemes:\")\n","        for k, v in over.items():\n","            report.append(f\"  {k}: {v['current']:.2f}% > {v['threshold']:.2f}%\")\n","\n","    return is_valid, under, over, \"\\n\".join(report)\n","\n","\n","# -----------------------\n","# Generator Function\n","# -----------------------\n","def generate_ust_lab(\n","    out_dir,\n","    filename,\n","    base_note,\n","    note_range,\n","    length_variant,\n","    extra_sp,\n","    length_mode=\"normal\",\n","    use_ratio_targets=False,\n","    blocked_phonemes=None,\n","    ust_flags=\"g0B0H0P86\" # New parameter for UST flags\n","):\n","    ust = list(UST_HEADER_TEMPLATE)  # Start with sample header\n","    lab = []\n","    if blocked_phonemes is None:\n","        blocked_phonemes = set()\n","\n","    note_idx = 0\n","    current_tick = 0\n","    current_time_ns = 0.0\n","\n","    # Track phoneme counts for ratio targeting\n","    phoneme_counts = Counter()\n","    total_phoneme_count = 0\n","\n","    def add_note_data(length, lyric, note_num, next_length=None, next_note=None):\n","        nonlocal note_idx, current_time_ns, phoneme_counts, total_phoneme_count\n","\n","        # 1. Append to UST (convert hiragana to romaji for UST)\n","        pbs, pbw, pby, pbm = generate_pitch_curve(\n","            length,\n","            note_num,\n","            next_length,\n","            next_note\n","        )\n","        vbr = vibrato_params()  # Random vibrato per note\n","        ust_lyric = hiragana_to_romaji(lyric) if lyric != \"SP\" else \"SP\"\n","\n","        # Build UST note entry\n","        note_entry = f\"\"\"[#%04d]\n","Length={length}\n","Lyric={ust_lyric}\n","NoteNum={note_num}\n","PreUtterance=\n","Velocity=100\n","Intensity=100\n","Modulation=0\n","Flags={ust_flags} # Use the ust_flags parameter here\n","PBS={pbs}\n","PBW={pbw}\n","PBY={pby}\n","PBM={pbm}\"\"\" % note_idx\n","\n","        # Add VBR only if vibrato is enabled\n","        if vbr:\n","            note_entry += f\"\\nVBR={vbr}\"\n","\n","        note_entry += \"\\n\"\n","        ust.append(note_entry)\n","\n","        note_idx += 1\n","\n","        # 2. Append to LAB (keep original hiragana for phoneme decomposition)\n","        phons = decompose_lyric(lyric)\n","        note_duration_ns = length * TICK_TO_100NS\n","\n","        # Note: Phonemes are already tracked during note collection if use_ratio_targets is enabled\n","        # This ensures weighted selection works correctly\n","\n","        if LAB_OUTPUT_FORMAT == 'htk':\n","            # Distribute duration among phonemes\n","            # Simple heuristic: Equal split for now (improving this requires alignment models)\n","            part_dur = note_duration_ns / len(phons)\n","\n","            for ph in phons:\n","                start_t = int(current_time_ns)\n","                end_t = int(current_time_ns + part_dur)\n","                lab.append(f\"{start_t} {end_t} {ph}\")\n","                current_time_ns += part_dur\n","        else:\n","            # Simple list format\n","            lab.extend(phons)\n","\n","    # Collect all notes first (excluding SP at start/end)\n","    notes = []\n","    temp_tick = SP_TICK  # Account for initial SP\n","\n","    while temp_tick < TOTAL_TICKS - SP_TICK:\n","        length = pick_length(length_mode)\n","        if temp_tick + length > TOTAL_TICKS - SP_TICK:\n","            break\n","\n","        # Use weighted selection if ratio targeting is enabled\n","        if use_ratio_targets:\n","            lyric = pick_lyric_weighted(\n","                current_counts=dict(phoneme_counts),\n","                total_count=total_phoneme_count,\n","                target_ratio=TARGET_RATIO,\n","                blocked_phonemes=blocked_phonemes\n","            )\n","            # Pre-track phonemes for this lyric to improve next selection\n","            phons = decompose_lyric(lyric)\n","            for ph in phons:\n","                if ph != \"SP\":\n","                    phoneme_counts[ph] += 1\n","                    total_phoneme_count += 1\n","        else:\n","            lyric = pick_lyric()\n","\n","        note = pick_note(base_note, note_range)\n","        notes.append((length, lyric, note))\n","        temp_tick += length\n","\n","    # Insert extra SP notes randomly between regular notes (not at start/end)\n","    if extra_sp > 0 and len(notes) > 0:\n","        # Calculate positions where SP can be inserted (between notes, not at edges)\n","        num_insert_positions = len(notes) - 1  # Between notes\n","        if num_insert_positions > 0:\n","            # Randomly select positions for SP insertion\n","            sp_positions = random.sample(\n","                range(num_insert_positions),\n","                min(extra_sp, num_insert_positions)\n","            )\n","            sp_positions.sort(reverse=True)  # Insert from end to maintain indices\n","\n","            # Insert SP notes at selected positions\n","            for pos in sp_positions:\n","                notes.insert(pos + 1, (SP_TICK, \"SP\", base_note))\n","\n","    # Add initial SP (with next note info if available)\n","    if notes:\n","        next_length, next_lyric, next_note = notes[0]\n","    else:\n","        next_length, next_note = None, None\n","    add_note_data(SP_TICK, \"SP\", base_note, next_length, next_note)\n","    current_tick += SP_TICK\n","\n","    # Add all notes (regular + inserted SP)\n","    for i, (length, lyric, note) in enumerate(notes):\n","        # Get next note info if available\n","        if i + 1 < len(notes):\n","            next_length, next_lyric, next_note = notes[i + 1]\n","        else:\n","            # Last note before final SP\n","            next_length, next_note = SP_TICK, base_note\n","        add_note_data(length, lyric, note, next_length, next_note)\n","        current_tick += length\n","\n","    # Add final SP (no next note)\n","    add_note_data(SP_TICK, \"SP\", base_note, None, None)\n","\n","    # Add TRACKEND to UST\n","    ust.append(\"[#TRACKEND]\")\n","\n","    out_dir = Path(out_dir)\n","    out_dir.mkdir(parents=True, exist_ok=True)\n","\n","    (out_dir / f\"{filename}.ust\").write_text(\"\\n\".join(ust), encoding=\"utf-8\")\n","\n","    if LAB_OUTPUT_FORMAT == 'htk':\n","        # Add trash phoneme at the end (very small duration, 100ns)\n","        if lab:\n","            # Get last end time from the last lab entry\n","            last_line = lab[-1]\n","            last_parts = last_line.strip().split()\n","            if len(last_parts) >= 2:\n","                last_end_time = int(last_parts[1])\n","                trash_start = last_end_time\n","                trash_end = trash_start + 100  # 100ns\n","                lab.append(f\"{trash_start} {trash_end} trash\")\n","        (out_dir / f\"{filename}.lab\").write_text(\"\\n\".join(lab), encoding=\"utf-8\")\n","    else:\n","        (out_dir / f\"{filename}.lab\").write_text(\" \".join(lab), encoding=\"utf-8\")\n","\n","# -----------------------\n","# Phoneme Counter Function\n","# -----------------------\n","def count_phonemes_from_lab_dir(lab_dir):\n","    \"\"\"\n","    Count all phonemes from all LAB files in a directory.\n","\n","    Args:\n","        lab_dir: Path to directory containing .lab files\n","\n","    Returns:\n","        dict: Dictionary with phoneme counts {phoneme: count}\n","    \"\"\"\n","    lab_dir = Path(lab_dir)\n","    if not lab_dir.exists():\n","        return {}\n","\n","    phoneme_counts = Counter()\n","    lab_files = list(lab_dir.glob(\"*.lab\"))\n","\n","    if not lab_files:\n","        return {}\n","\n","    for lab_file in lab_files:\n","        try:\n","            with open(lab_file, 'r', encoding='utf-8') as f:\n","                content = f.read().strip()\n","                if not content:\n","                    continue\n","\n","                lines = content.split('\\n')\n","                # Check if HTK format (first line has numeric start/end times)\n","                first_line_parts = lines[0].strip().split()\n","                is_htk = (len(first_line_parts) >= 3 and\n","                         first_line_parts[0].replace('.', '', 1).isdigit())\n","\n","                if is_htk:\n","                    # HTK format: start_time end_time phoneme\n","                    for line in lines:\n","                        parts = line.strip().split()\n","                        if len(parts) >= 3:\n","                            phoneme = parts[2]  # Third element is the phoneme\n","                            # Exclude SP phonemes from statistics\n","                            if phoneme != \"SP\":\n","                                phoneme_counts[phoneme] += 1\n","                else:\n","                    # Simple format: space-separated phonemes\n","                    phonemes = content.split()\n","                    for phoneme in phonemes:\n","                        # Exclude SP phonemes from statistics\n","                        if phoneme != \"SP\":\n","                            phoneme_counts[phoneme] += 1\n","        except Exception as e:\n","            print(f\"Warning: Could not read {lab_file}: {e}\")\n","            continue\n","\n","    return dict(phoneme_counts)\n","\n","\n","# -----------------------\n","# Prepare Output Folder\n","# -----------------------\n","output_root = Path(MOUNTED_DRIVE_DIR) / FILE_PREFIX\n","# Ensure output_root is empty at the start\n","if output_root.exists() and output_root.is_dir():\n","    shutil.rmtree(output_root)\n","\n","output_root.mkdir(parents=True, exist_ok=True)\n","blocked_phonemes = set()\n","\n","# -----------------------\n","# Generate UST + LAB\n","# -----------------------\n","for i in range(1, BATCH_COUNT + 1):\n","    base_note = pick_base_note_gaussian(\n","      base_note_min=BASE_NOTE_MIN,\n","      base_note_max=BASE_NOTE_MAX,\n","      batch_count=BATCH_COUNT,\n","      sigma_scale=SIGMA_VALUE\n","    )\n","    note_range = random.randint(*NOTE_RANGE_RANGE)\n","    length_variant = round(random.uniform(*LENGTH_VARIANT_RANGE), 2)\n","    extra_sp = random.randint(*EXTRA_SP_RANGE)\n","    length_mode = random.choice(LENGTH_MODES)  # Randomly select length mode\n","\n","    base_note_name = midi_to_note_name(base_note)\n","    filename = f\"{PREFIX}{i:03d}_{base_note_name}_{note_range}\"\n","\n","    # phoneme_counts is reset for each individual UST validation iteration in the loop\n","    # but for overall statistics, `counts` below will re-read all generated files\n","\n","    generate_ust_lab(\n","        out_dir=output_root,\n","        filename=filename,\n","        base_note=base_note,\n","        note_range=note_range,\n","        length_variant=length_variant,\n","        extra_sp=extra_sp,\n","        length_mode=length_mode,\n","        use_ratio_targets=True,\n","        blocked_phonemes=blocked_phonemes,\n","        ust_flags=UST_FLAGS # Pass the user-defined UST_FLAGS\n","    )\n","\n","    # Validate THIS UST\n","    counts = count_phonemes_from_lab_dir(output_root)\n","\n","    valid, under, over, report = validate_phoneme_ratios(\n","        counts,\n","        TARGET_RATIO\n","    )\n","\n","    print(f\"\\nUST {filename} validation:\")\n","    print(report)\n","\n","    # Feed back overrepresented phonemes to block them in subsequent generations\n","    blocked_phonemes = set(over.keys())\n","\n","# -----------------------\n","# Zip Output\n","# -----------------------\n","zip_path = Path(MOUNTED_DRIVE_DIR) / f\"{FILE_PREFIX}.zip\"\n","\n","if zip_path.exists():\n","    zip_path.unlink()\n","\n","shutil.make_archive(\n","    base_name=str(zip_path).replace(\".zip\", \"\"),\n","    format=\"zip\",\n","    root_dir=output_root\n",")\n","\n","# -----------------------\n","# Count Phonemes\n","# -----------------------\n","print(f\"\\nBatch generation complete.\")\n","print(f\"Zipped dataset saved to:\\n{zip_path}\")\n","\n","phoneme_counts = count_phonemes_from_lab_dir(output_root)\n","if phoneme_counts:\n","    total_phonemes = sum(phoneme_counts.values())\n","    print(f\"\\n{'='*50}\")\n","    print(f\"PHONEME STATISTICS\")\n","    print(f\"{'='*50}\")\n","    print(f\"Total phonemes: {total_phonemes}\")\n","    print(f\"Unique phonemes: {len(phoneme_counts)}\")\n","    print(f\"\\nPhoneme counts (sorted by frequency):\")\n","    print(f\"{'-'*50}\")\n","    for phoneme, count in sorted(phoneme_counts.items(), key=lambda x: x[1], reverse=True):\n","        percentage = (count / total_phonemes) * 100\n","        print(f\"  {phoneme:10s}: {count:6d} ({percentage:5.2f}%)\")\n","    print(f\"{'='*50}\")\n","\n","    # Validate phoneme ratios\n","    print(f\"\\n{'='*50}\")\n","    print(f\"PHONEME RATIO VALIDATION\")\n","    print(f\"{'='*50}\")\n","    is_valid, under, over, report = validate_phoneme_ratios(phoneme_counts, TARGET_RATIO, under_threshold=0.7)\n","    print(f\"Validation: {'PASS' if is_valid else 'FAIL'}\")\n","    print(report)\n","    print(f\"{'='*50}\")\n","else:\n","    print(\"\\nNo LAB files found to count phonemes.\")"]},{"cell_type":"code","source":["#@markdown # ðŸ›  USTX Transform\n","#@markdown\n","#@markdown This tool fixes and normalizes **USTX files** generated from imported USTs,\n","#@markdown making them **dataset-ready** for easier WAV export and DiffSinger / OpenUtau workflows.\n","#@markdown\n","#@markdown ---\n","#@markdown\n","#@markdown ## âœ¨ What This Script Does\n","#@markdown\n","#@markdown When executed, this script will:\n","#@markdown\n","#@markdown - âœ… **Automatically rename singer tracks**\n","#@markdown   - Track names are derived from associated `voice_parts`\n","#@markdown   - Example:\n","#@markdown     - `singer_neutral_001_A3_9` â†’ `001_A3_9`\n","#@markdown\n","#@markdown - ðŸ” **Propagate singer settings forward**\n","#@markdown   - Tracks without a `singer` will inherit:\n","#@markdown     - singer\n","#@markdown     - phonemizer\n","#@markdown     - renderer_settings\n","#@markdown     - voice_color_names\n","#@markdown     - track_expressions\n","#@markdown   - Source is the nearest previous singer track\n","#@markdown\n","#@markdown - ðŸŽ› **Replicate phoneme expressions**\n","#@markdown   - `phoneme_expressions` from:\n","#@markdown     - **Track 1 (index 0) â†’ First Note**\n","#@markdown   - Are copied to:\n","#@markdown     - all notes\n","#@markdown     - all voice parts\n","#@markdown     - all tracks\n","#@markdown\n","#@markdown This ensures **consistent expression behavior** and **clean track naming**\n","#@markdown for batch WAV export.\n","#@markdown\n","#@markdown ---\n","#@markdown\n","#@markdown ## ðŸ“¦ Prerequisites\n","#@markdown\n","#@markdown Before running the script, make sure:\n","#@markdown\n","#@markdown 1. You have a valid **`.ustx` file**\n","#@markdown    - Generated by importing UST files\n","#@markdown\n","#@markdown 2. **Track 1 (index 0) is fully configured**\n","#@markdown    - Must already contain:\n","#@markdown      - `singer`\n","#@markdown      - `phonemizer`\n","#@markdown      - renderer settings\n","#@markdown\n","#@markdown 3. Expression replication (optional)\n","#@markdown    - If you want expressions copied, set them on:\n","#@markdown      - **Track 1 â†’ First Note**\n","#@markdown    - Examples:\n","#@markdown      - Gender\n","#@markdown      - Velocity\n","#@markdown      - Dynamics\n","#@markdown      - moresampler parameters (`Mt`, `Mb`, `Mo`, etc.)\n","#@markdown\n","#@markdown âš ï¸ Only expressions present on the **first note of Track 1**\n","#@markdown will be propagated.\n","#@markdown\n","#@markdown ---\n","#@markdown\n","#@markdown ## â–¶ï¸ How to Use\n","#@markdown\n","#@markdown ### Step 1 â€” Run the Cell\n","#@markdown Run the cell containing the **USTX Fixer** script.\n","#@markdown\n","#@markdown ---\n","#@markdown\n","#@markdown ### Step 2 â€” Upload Your USTX\n","#@markdown A file upload prompt will appear.\n","#@markdown\n","#@markdown - Select the `.ustx` file you want to transform\n","#@markdown\n","#@markdown ---\n","#@markdown\n","#@markdown ### Step 3 â€” Automatic Processing\n","#@markdown The script will:\n","#@markdown\n","#@markdown - Load the uploaded USTX\n","#@markdown - Apply all transformations:\n","#@markdown   - track renaming\n","#@markdown   - singer propagation\n","#@markdown   - phoneme expression replication\n","#@markdown\n","#@markdown Progress messages will be printed in the output cell.\n","#@markdown\n","#@markdown ---\n","#@markdown\n","#@markdown ### Step 4 â€” Download Result\n","#@markdown After processing completes:\n","#@markdown\n","#@markdown - A new file will be generated:\n","#@markdown\n","#@markdown   `<original_name>_dataset.ustx`\n","#@markdown\n","#@markdown - The browser will automatically download the transformed file\n","#@markdown\n","#@markdown ---\n","#@markdown\n","#@markdown ## âœ… Result\n","#@markdown\n","#@markdown You will get a **clean, dataset-ready USTX** with:\n","#@markdown\n","#@markdown - Properly named tracks\n","#@markdown - Consistent singer and expression settings\n","#@markdown - Ready for batch WAV export or DiffSinger processing\n","#@markdown\n","#@markdown ---\n","#@markdown\n","#@markdown ## ðŸ§© Notes & Tips\n","#@markdown\n","#@markdown - Each singer track is renamed **only once**\n","#@markdown - Phonemizer-only tracks are preserved\n","#@markdown - Safe to re-run on the same file (mostly idempotent)\n","#@markdown\n","#@markdown ---\n","#@markdown\n","\n","from google.colab import files\n","import yaml\n","import copy\n","import os\n","\n","# ---------------------------\n","# Helper: extract track name\n","# ---------------------------\n","def extract_track_name_from_voicepart(name: str) -> str:\n","    \"\"\"\n","    mzo_neutral_001_A3_9 -> 001_A3_9\n","    \"\"\"\n","    parts = name.split(\"_\")\n","    return \"_\".join(parts[-3:]) if len(parts) >= 3 else name\n","\n","def propagate_phoneme_expressions_from_first_note(voice_parts):\n","    \"\"\"\n","    Copy voice_parts[0].notes[0].phoneme_expressions\n","    to all notes in all other voice_parts.\n","    \"\"\"\n","    if (\n","        not voice_parts\n","        or not voice_parts[0].get(\"notes\")\n","        or not voice_parts[0][\"notes\"][0].get(\"phoneme_expressions\")\n","    ):\n","        print(\"â„¹ No phoneme_expressions to propagate\")\n","        return\n","\n","    template = copy.deepcopy(\n","        voice_parts[0][\"notes\"][0][\"phoneme_expressions\"]\n","    )\n","\n","    for vp_index, vp in enumerate(voice_parts):\n","        if vp_index == 0:\n","            continue\n","\n","        for note in vp.get(\"notes\", []):\n","            note[\"phoneme_expressions\"] = copy.deepcopy(template)\n","\n","        print(f\"âœ” Applied phoneme_expressions â†’ voice_parts[{vp_index}]\")\n","\n","def propagate_singers_forward(tracks):\n","    \"\"\"\n","    For tracks without 'singer', copy singer-related fields\n","    from the nearest previous singer track.\n","    \"\"\"\n","    last_singer_track = None\n","\n","    for i, track in enumerate(tracks):\n","        if \"singer\" in track:\n","            last_singer_track = track\n","            continue\n","\n","        if last_singer_track is not None:\n","            # Copy all singer-related keys\n","            for key in (\n","                \"singer\",\n","                \"phonemizer\",\n","                \"renderer_settings\",\n","                \"voice_color_names\",\n","                \"track_expressions\",\n","            ):\n","                if key in last_singer_track:\n","                    track[key] = copy.deepcopy(last_singer_track[key])\n","\n","            print(f\"âž• Inherited singer for tracks[{i}] from previous singer\")\n","\n","\n","\n","\n","\n","# ---------------------------\n","# Core processing function\n","# ---------------------------\n","def update_track_names_from_voiceparts(ustx: dict) -> dict:\n","    new_ustx = copy.deepcopy(ustx)\n","\n","    def find_previous_singer_track(tracks, start_index):\n","      \"\"\"\n","      Walk backward from start_index to find the nearest singer track.\n","      \"\"\"\n","      for i in range(start_index, -1, -1):\n","          if \"singer\" in tracks[i]:\n","              return tracks[i]\n","      return None\n","\n","    def find_previous_singer_track_index(tracks, start_index):\n","      for i in range(start_index, -1, -1):\n","          if \"singer\" in tracks[i]:\n","              return i\n","      return None\n","\n","\n","    tracks = new_ustx.get(\"tracks\", [])\n","    voice_parts = new_ustx.get(\"voice_parts\", [])\n","    print(f\"Found {len(tracks)} tracks and {len(voice_parts)} voice parts.\")\n","\n","    # ðŸ”¥ THIS IS THE MISSING STEP\n","    propagate_singers_forward(tracks)\n","\n","    propagate_phoneme_expressions_from_first_note(voice_parts)\n","\n","    # Only singer tracks (skip phonemizer-only tracks)\n","    singer_tracks = [t for t in tracks if \"singer\" in t]\n","\n","\n","    updated_singer_tracks = set()\n","\n","    for vp in voice_parts:\n","        track_no = vp.get(\"track_no\")\n","        vp_name = vp.get(\"name\")\n","\n","        track_index = track_no\n","        singer_index = find_previous_singer_track_index(tracks, track_index)\n","\n","        if singer_index is None:\n","            continue\n","\n","        # ðŸ”’ Prevent overwriting the same singer repeatedly\n","        if singer_index in updated_singer_tracks:\n","            continue\n","\n","        new_name = extract_track_name_from_voicepart(vp_name)\n","        tracks[singer_index][\"track_name\"] = new_name\n","        updated_singer_tracks.add(singer_index)\n","\n","        print(f\"âœ” Updated tracks[{singer_index}].track_name â†’ {new_name}\")\n","\n","\n","    return new_ustx\n","\n","\n","# ---------------------------\n","# Upload file\n","# ---------------------------\n","uploaded = files.upload()\n","ustx_path = list(uploaded.keys())[0]\n","\n","print(f\"Loaded: {ustx_path}\")\n","\n","# ---------------------------\n","# Read, process, write\n","# ---------------------------\n","with open(ustx_path, \"r\", encoding=\"utf-8\") as f:\n","    ustx_data = yaml.safe_load(f)\n","\n","fixed_ustx = update_track_names_from_voiceparts(ustx_data)\n","\n","output_path = os.path.splitext(ustx_path)[0] + \"_dataset.ustx\"\n","\n","with open(output_path, \"w\", encoding=\"utf-8\") as f:\n","    yaml.dump(\n","        fixed_ustx,\n","        f,\n","        allow_unicode=True,\n","        sort_keys=False\n","    )\n","\n","print(f\"Saved: {output_path}\")\n","\n","# ---------------------------\n","# Download result\n","# ---------------------------\n","files.download(output_path)"],"metadata":{"id":"b1XNHlcmnAmS"},"execution_count":null,"outputs":[]}]}